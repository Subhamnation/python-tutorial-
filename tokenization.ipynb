{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba97d303",
   "metadata": {},
   "source": [
    "#### Difference between NLTK and SpaCy in Python\n",
    "- NLTK (Natural Language Toolkit) and SpaCy are both popular libraries for natural language processing (NLP) in Python, but they have different design philosophies and use cases.\n",
    "\n",
    "- NLTK is more focused on providing a wide range of tools and resources for linguistic research and education. It includes functionalities for text processing, classification, tokenization, stemming, tagging, parsing, and more. NLTK is highly customizable and allows users to experiment with different algorithms and techniques.\n",
    "\n",
    "- SpaCy, on the other hand, is designed for industrial-strength NLP tasks and emphasizes performance and efficiency. It provides pre-trained models for various languages and is optimized for speed and ease of use. SpaCy is often preferred for production applications where quick and accurate results are required.\n",
    "\n",
    "- In summary, NLTK is a versatile toolkit for NLP research and education, while SpaCy is a powerful library for building real-world NLP applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cb625ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/subhamchakraborty/anaconda3/envs/open3d_env/lib/python3.10/site-packages (3.9.2)\n",
      "Requirement already satisfied: click in /home/subhamchakraborty/anaconda3/envs/open3d_env/lib/python3.10/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/subhamchakraborty/anaconda3/envs/open3d_env/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/subhamchakraborty/anaconda3/envs/open3d_env/lib/python3.10/site-packages (from nltk) (2025.7.34)\n",
      "Requirement already satisfied: tqdm in /home/subhamchakraborty/anaconda3/envs/open3d_env/lib/python3.10/site-packages (from nltk) (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34776290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, welcome to Subham Chakraborty's fantasy world.\n",
      "Please do remember it is an interesting and amazing world altogether.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus = \"\"\"Hello, welcome to Subham Chakraborty's fantasy world.\n",
    "Please do remember it is an interesting and amazing world altogether.\n",
    "\"\"\"\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "478dc412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/subhamchakraborty/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/subhamchakraborty/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tokenization\n",
    "\n",
    "## Sentence -> paragraphs \n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk \n",
    "nltk.download('punkt') # Downloads the punkt tokenizer\n",
    "nltk.download('punkt_tab') # Downloads the punkt tokenizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ceb2510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Hello, welcome to Subham Chakraborty's fantasy world.\", 'Please do remember it is an interesting and amazing world altogether.']\n"
     ]
    }
   ],
   "source": [
    "documents = sent_tokenize(corpus) \n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f524b603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "552c981b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, welcome to Subham Chakraborty's fantasy world.\n",
      "Please do remember it is an interesting and amazing world altogether.\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6e18d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization techniques\n",
    "\n",
    "# paragraph --> words \n",
    "# sentence --> words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3451e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " ',',\n",
       " 'welcome',\n",
       " 'to',\n",
       " 'Subham',\n",
       " 'Chakraborty',\n",
       " \"'s\",\n",
       " 'fantasy',\n",
       " 'world',\n",
       " '.',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'remember',\n",
       " 'it',\n",
       " 'is',\n",
       " 'an',\n",
       " 'interesting',\n",
       " 'and',\n",
       " 'amazing',\n",
       " 'world',\n",
       " 'altogether',\n",
       " '.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(corpus) # returns a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a66f765a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'welcome', 'to', 'Subham', 'Chakraborty', \"'s\", 'fantasy', 'world', '.']\n",
      "['Please', 'do', 'remember', 'it', 'is', 'an', 'interesting', 'and', 'amazing', 'world', 'altogether', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a39a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09058247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " ',',\n",
       " 'welcome',\n",
       " 'to',\n",
       " 'Subham',\n",
       " 'Chakraborty',\n",
       " \"'\",\n",
       " 's',\n",
       " 'fantasy',\n",
       " 'world',\n",
       " '.',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'remember',\n",
       " 'it',\n",
       " 'is',\n",
       " 'an',\n",
       " 'interesting',\n",
       " 'and',\n",
       " 'amazing',\n",
       " 'world',\n",
       " 'altogether',\n",
       " '.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus) # returns a list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dddcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"H e l l o,   w e l c o m e   t o   S u b h a m   C h a k r a b o r t y' s   f a n t a s y   w o r l d . \\n P l e a s e   d o   r e m e m b e r   i t   i s   a n   i n t e r e s t i n g   a n d   a m a z i n g   w o r l d   a l t o g e t h e r.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordDetokenizer # for tokenization\n",
    "tokenizer = TreebankWordDetokenizer() \n",
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef41926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open3d_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
